<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-02-14">

<title>Object Recognition Using AlexNet – Akshat’s Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-138cb3c0419abe8778c1973ca33717ae.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Akshat’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Object Recognition Using AlexNet</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">ml</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 14, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#the-imagenet-object-recognition-task" id="toc-the-imagenet-object-recognition-task" class="nav-link" data-scroll-target="#the-imagenet-object-recognition-task">The ImageNet object recognition task</a></li>
  <li><a href="#alexnet-architecture" id="toc-alexnet-architecture" class="nav-link" data-scroll-target="#alexnet-architecture">AlexNet architecture</a></li>
  <li><a href="#speeding-up-training-model-parallelism" id="toc-speeding-up-training-model-parallelism" class="nav-link" data-scroll-target="#speeding-up-training-model-parallelism">Speeding up training: model parallelism</a></li>
  <li><a href="#speeding-up-training-rectified-linear-unit-relu" id="toc-speeding-up-training-rectified-linear-unit-relu" class="nav-link" data-scroll-target="#speeding-up-training-rectified-linear-unit-relu">Speeding up training: Rectified Linear Unit (ReLU)</a></li>
  <li><a href="#preventing-overfitting-dropout" id="toc-preventing-overfitting-dropout" class="nav-link" data-scroll-target="#preventing-overfitting-dropout">Preventing overfitting: Dropout</a></li>
  <li><a href="#preventing-overfitting-data-augmentation" id="toc-preventing-overfitting-data-augmentation" class="nav-link" data-scroll-target="#preventing-overfitting-data-augmentation">Preventing overfitting: Data augmentation</a></li>
  <li><a href="#training-utilities" id="toc-training-utilities" class="nav-link" data-scroll-target="#training-utilities">Training utilities</a></li>
  <li><a href="#training-stochastic-gradient-descent-with-weight-decay" id="toc-training-stochastic-gradient-descent-with-weight-decay" class="nav-link" data-scroll-target="#training-stochastic-gradient-descent-with-weight-decay">Training: Stochastic Gradient Descent with Weight Decay</a></li>
  <li><a href="#training-learning-rate-schedule" id="toc-training-learning-rate-schedule" class="nav-link" data-scroll-target="#training-learning-rate-schedule">Training: Learning Rate Schedule</a></li>
  <li><a href="#training-loop" id="toc-training-loop" class="nav-link" data-scroll-target="#training-loop">Training loop</a></li>
  <li><a href="#execution" id="toc-execution" class="nav-link" data-scroll-target="#execution">Execution</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>In the previous blog post, we implemented Lenet-5, which was released in 1998. The next big breakthrough for deep learning came in 2012, with the release of AlexNet. Jointly authored by Alex Krizhevsky, after whom the model is named, with Ilya Sutskever and Geoffrey Hinton, AlexNet won the Imagenet competition in 2012 by a very big margin, demonstrating that deep learning approaches could be the state-of-the art in computer vision tasks. In this post, we will reimplement the AlexNet architecture with close reference to the original paper. We will try to stay as faithful to the published version as possible, but wherever we deviate, we will be careful to document it. The major discovery of AlexNet, which we will try to convey, is that training deep neural networks with many layers could dramatically increase performance, and the compute required to train neural networks of interesting depth could be provided by graphics programming units (GPUs).</p>
<div id="4143c365-6f2b-40bd-9166-8e2f40dd5e9a" class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import packages</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.datasets <span class="im">as</span> datasets</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils <span class="im">import</span> data</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.multiprocessing</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.datasets <span class="im">as</span> datasets</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> livelossplot <span class="im">import</span> PlotLosses</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="the-imagenet-object-recognition-task" class="level1">
<h1>The ImageNet object recognition task</h1>
<p>The ImageNet dataset consists of 1.5 million images labelled with 1000 different classes. A famous machine learning competition called the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) asks submissions to recognize or in other words classify an image into the different classes.</p>
<p>The primary metrics that the competition used were the top-5 error and top-1 error, which are defined respectively as follows: the submissions can make up to 5 predictions per image from the 1000 classes, and a top-5 error is defined to have happened when the correct class is not present in these predictions. The top-1 error is equivalent to the accuracy: the submissions can make one prediction per image from the 1000 classes, and a top-1 error is defined to have happened when the correct class is not equal to this prediction.</p>
<div id="05c0b23b-f3bd-432f-8687-e7700afb6d91" class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_dataset(IMG_DIR, transforms_list):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Get dataset</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> datasets.ImageFolder(IMG_DIR, transforms.Compose(transforms_list))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="5d9e5d96-86e5-4688-bf95-d9e9c0e312fa" class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_dataloader(dataset, BATCH_SIZE, shuffle<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>                   pin_memory<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">4</span>, </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>                   drop_last<span class="op">=</span><span class="va">True</span>, subset_data<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>                   N_SAMPLE<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Get data-loader</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> subset_data <span class="op">==</span> <span class="va">True</span>:</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> N_SAMPLE <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        subset <span class="op">=</span> random.sample(<span class="bu">range</span>(<span class="bu">len</span>(dataset)), N_SAMPLE)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        dataset <span class="op">=</span> data.Subset(dataset, subset)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data.DataLoader(</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>                    dataset,</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>                    shuffle<span class="op">=</span>shuffle,</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>                    pin_memory<span class="op">=</span>pin_memory,</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>                    num_workers<span class="op">=</span>num_workers,</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>                    drop_last<span class="op">=</span>drop_last,</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>                    batch_size<span class="op">=</span>BATCH_SIZE)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>ImageNet was considered a very hard dataset, because classical machine learning methods were not able to do well at this task. AlexNet won the 2012 challenge, doing better than the other submissions by a huge margin. In the next section, we’ll start explaining the architecture and the innovations in the paper which made this jump in performance possible.</p>
</section>
<section id="alexnet-architecture" class="level1">
<h1>AlexNet architecture</h1>
<p>ImageNet is so large that reaching good performance on object recognition requires a model far deeper, with more layers and more filters per layer, than had been trained at the time. The AlexNet architecture consists of five convolutional layers followed by three fully connected layers, which seems small by today’s standards but was very large by the standards of that time. Training this architecture on a CPU or even a single GPU for long enough to reach a good level of performance was infeasible with the hardware then available. The designers of AlexNet realized that they would have to get creative to get good results, and so they came up with many tricks to speed up training, some of which we talk about below.</p>
<div id="fc3ad8ac-852f-4aff-aa49-e118e156fdc7" class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AlexNet(nn.Module):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes):</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(AlexNet, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.net <span class="op">=</span> nn.Sequential(</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 3 * 224 * 224</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(in_channels<span class="op">=</span><span class="dv">3</span>, out_channels<span class="op">=</span><span class="dv">96</span>, kernel_size<span class="op">=</span><span class="dv">11</span>, stride<span class="op">=</span><span class="dv">4</span>), </span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Size: (224 + 2*2 - 8) / 2 + 1 = (110 + 1) = 111</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 64 * 111 * 111</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 64 * 111 * 111</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>            nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Size: (111 + 2*0 - 3) / 1 + 1 = (108 + 1) = 109</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 64 * 109 * 109 </span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(in_channels<span class="op">=</span><span class="dv">96</span>, out_channels<span class="op">=</span><span class="dv">256</span>, kernel_size<span class="op">=</span><span class="dv">5</span>, padding<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Size: (109 + 2*2 - 5) / 1 + 1 = (108 + 1) = 109</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 64 * 109 * 109</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Size: (109 + 2*2 - 5) / 1 + 1 = (108 + 1) = 109</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 64 * 109 * 109</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>            nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">2</span>), </span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Size: (109 + 2*0 - 3) / 2 + 1 = (53 + 1) = 54</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 128 * 54 * 54</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(in_channels<span class="op">=</span><span class="dv">256</span>, out_channels<span class="op">=</span><span class="dv">384</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Size: (54 + 2*1 - 3) / 1 + 1 = (53 + 1) = 54</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 128 * 54 * 54</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Size: (54 + 2*1 - 3) / 1 + 1 = (53 + 1) = 54</span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 256 * 54 * 54</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(in_channels<span class="op">=</span><span class="dv">384</span>, out_channels<span class="op">=</span><span class="dv">384</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Size: (54 + 2*1 - 3) / 1 + 1 = (53 + 1) = 54</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 256 * 54 * 54</span></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Size: (54 + 2*1 - 3) / 1 + 1 = (53 + 1) = 54</span></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 256 * 54 * 54</span></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(in_channels<span class="op">=</span><span class="dv">384</span>, out_channels<span class="op">=</span><span class="dv">256</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Size: (54 + 2*1 - 3) / 1 + 1 = (53 + 1) = 54</span></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 256 * 54 * 54</span></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Size: (54 + 2*1 - 3) / 1 + 1 = (53 + 1) = 54</span></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 256 * 54 * 54</span></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>            nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Size: (54 - 3) / 2 + 1 = (53 + 1) = 54</span></span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 256 * 54 * 54</span></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>            ) </span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.classifier <span class="op">=</span> nn.Sequential(</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>            nn.Flatten(),</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(),</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>            nn.Linear(in_features<span class="op">=</span><span class="dv">256</span> <span class="op">*</span> <span class="dv">6</span> <span class="op">*</span> <span class="dv">6</span>, out_features<span class="op">=</span><span class="dv">4096</span>),</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(),</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>            nn.Linear(in_features<span class="op">=</span><span class="dv">4096</span>, out_features<span class="op">=</span><span class="dv">4096</span>), </span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a>            nn.Linear(in_features<span class="op">=</span><span class="dv">4096</span>, out_features<span class="op">=</span>num_classes)</span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.init_weights()</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> init_weights(<span class="va">self</span>):</span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>.net:</span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(layer, nn.Conv2d):</span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a>                nn.init.normal_(layer.weight, mean<span class="op">=</span><span class="dv">0</span>, std<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a>                nn.init.constant_(layer.bias, <span class="dv">0</span>)</span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(layer, nn.Linear):</span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a>                nn.init.normal_(layer.weight, mean<span class="op">=</span><span class="dv">0</span>, std<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a>                nn.init.constant_(layer.bias, <span class="dv">1</span>)</span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a>        nn.init.constant_(<span class="va">self</span>.net[<span class="dv">3</span>].bias, <span class="dv">1</span>)</span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a>        nn.init.constant_(<span class="va">self</span>.net[<span class="dv">6</span>].bias, <span class="dv">1</span>)</span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a>        nn.init.constant_(<span class="va">self</span>.net[<span class="dv">8</span>].bias, <span class="dv">1</span>)</span>
<span id="cb4-75"><a href="#cb4-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-76"><a href="#cb4-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-77"><a href="#cb4-77" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb4-78"><a href="#cb4-78" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.net(x)</span>
<span id="cb4-79"><a href="#cb4-79" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.classifier(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="speeding-up-training-model-parallelism" class="level1">
<h1>Speeding up training: model parallelism</h1>
<p>One main innovation of the paper was coming up with a way to do parallel training across two GPUs. The authors designed a model parallelism scheme. Model parallelism refers to placing different parts of a model’s architecture on different machines and training them in parallel. In AlexNet, inputs to deeper layers come only from those layers which reside on the same GPU. For example, layer 4 takes input only from those layer 3 kernels which are on the same machine.</p>
<p>A second innovation contributed by the authors was writing highly efficient implementations of all the operations required in the architecture in CUDA, the API for interacting with NVIDIA GPUs. At the time of writing, this code is still available on Alex Krizhevsky’s website. The authors had realized that GPUs could be leveraged to make training feasible for deeper architectures, and that making optimal use of the hardware available would be key. This is why the authors put a lot of effort into getting the GPU code right.</p>
<p>Throughout the paper, the authors have to balance the need for depth and training time with the computational resources available to them. That tension between scaling up compute while retaining efficiency has become a theme of deep learning research that continues until today.</p>
</section>
<section id="speeding-up-training-rectified-linear-unit-relu" class="level1">
<h1>Speeding up training: Rectified Linear Unit (ReLU)</h1>
<p>AlexNet was amongst the first major models to use the ReLU activation function, instead of the sigmoid or tanh functions which were commonly used in deep learning models at that time. The ReLU activation function allows for learning to occur at any positive value of the activation. The sigmoid or tanh functions have lower gradients at extreme values, which leads to a relatively higher proportion of ‘dead’ neurons which are not contributing to learning. The graph below exhibits this.</p>
<div id="ecb2c452-997f-4ebe-8eaf-31d0cb501347" class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> activation_plot(start, end, step):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Activation plot</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> torch.arange(start,end, step)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    sigmoid <span class="op">=</span> nn.Sigmoid()(x)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    tanh <span class="op">=</span> nn.Tanh()(x)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    relu <span class="op">=</span> nn.ReLU()(x)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> y <span class="kw">in</span> [sigmoid, tanh, relu]:</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        plt.plot(x, y, c<span class="op">=</span>cdict[i], label<span class="op">=</span>labels[i])</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        i<span class="op">+=</span><span class="dv">1</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="07eb3e0e-6372-484e-a552-e9dec7e3cd72" class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> <span class="op">-</span><span class="dv">2</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>end <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>step <span class="op">=</span> <span class="fl">1e-4</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>cdict <span class="op">=</span> {<span class="dv">1</span>: <span class="st">'red'</span>, <span class="dv">2</span>: <span class="st">'blue'</span>, <span class="dv">3</span>: <span class="st">'green'</span>}</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> {<span class="dv">1</span>: <span class="st">'sigmoid'</span>, <span class="dv">2</span>: <span class="st">'tanh'</span>, <span class="dv">3</span>: <span class="st">'relu'</span>}</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>activation_plot(start, end, step)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="alexnet_files/figure-html/cell-7-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>What does it mean to say a neuron is dead? It means that the particular neuron is not contributing a significant amount to the steps taken by the optimizer. Suppose we are training a model using stochastic gradient descent, like the authors of AlexNet did. The update formula is given as follows:</p>
<p><span class="math inline">\(W^{(l)} \leftarrow W^{(l)} - \eta \frac{\partial L}{\partial W^{(l)}}\)</span></p>
<p>From the chain rule:</p>
<p><span class="math inline">\(\frac{\partial L}{\partial W^{(l)}} = \frac{\partial L}{\partial a^{(l)}} \times \frac{\partial a^{(l)}}{\partial W^{(l)}}\)</span></p>
<p>From the formulas, we see that the step size is determined by two quantities: the learning rate <span class="math inline">\(\eta\)</span> and the gradient of the loss with respect to the weights <span class="math inline">\(\frac{\partial L}{\partial W^{(l)}}\)</span>. Using the chain rule, the gradient of the loss with respect to the weights is the gradient of the activation with respect to the weight <span class="math inline">\(\frac{\partial a^{(l)}}{\partial W^{(l)}}\)</span> times the gradient of the loss with respect to the activation <span class="math inline">\(\frac{\partial L}{\partial a^{(l)}}\)</span>.</p>
<p>If the activation function has a small gradient with respect to the weights, that reduces the contribution of that particular neuron to the overall step taken by the optimizer for a fixed learning rate and fixed activation function. At extreme values of the activation, look at the graph above - the gradients of the sigmoid and tanh are very small! This leads to a lower learning rate and slower training.</p>
<p>The ReLU function is designed to address this problem, and the paper shows evidence from experiments that this actually works. Another interesting way to solve this problem is to use learning rates which vary throughout the training as a function of the epoch number, and also across layers, depending on how many neurons are ‘dying’. Maybe there will another blog post which covers this set of very cool ideas.</p>
</section>
<section id="preventing-overfitting-dropout" class="level1">
<h1>Preventing overfitting: Dropout</h1>
<p>Given that the authors were training a model with more layers than was usual for that time, the other concern was to control overfitting. Overfitting in machine learning refers to a situation where a model learns to ‘memorize’ the training data so closely that it does not generalize well to unseen validation or test data. The solution is to use regularization, or in other words, restrict the complexity of the model, to force it to learn only those features or weights which are actually useful in performing the task that is being solved.</p>
<p>One interesting regularization method is dropout. Training ensembles of models, or in other words multiple architectures, had been shown by that time to generalize better for many different kinds of machine learning models. However, for a neural network like this, which was already taking days to train, training multiple architectures was infeasible.</p>
<p>Dropout had at the time been recently proposed as a way to simulate an ensemble. In dropout, hidden layer neuron outputs are randomly set to 0 with probability 0.5. This randomly deactivates certain neurons per layer in both the forward and backward pass, and so with each iteration, the training procedure is effectively using a different architecture. This also ensures that the remaining neurons do not co-adapt to each other - each neuron which survives the dropout layer in a given forward pass is forced to learn more robust and relevant features in conjunction with other random subsets of neurons, so it does not become too specialized. At test time, the output of each hidden layer neuron is multiplied by 0.5, and no neurons are discarded. This is so that the test time prediction distribution matches the training time distribution.</p>
</section>
<section id="preventing-overfitting-data-augmentation" class="level1">
<h1>Preventing overfitting: Data augmentation</h1>
<p>Data augmentation is a second technique used by the paper. The ImageNet images are high resolution 256 X 256 images. The authors cut out random 226 X 226 center patches from the image and perform two types of augmentation: 1) translations and inversions, and 2) changing the color and illumination of each extracted patch according to a particular scheme that they define. This increases the size of the training data by a factor of 2048x, though obviously there is a high correlation between many of the resulting samples. The paper reports that the model severely overfits without data augmentation. At test time, the model makes predictions on five 226 X 226 patches. These are the four corner patches of that size and the center patch.</p>
<p>To change the color and illumination, the paper uses a scheme where it takes all the RGB pixel values across the training set, calculates the principle components via PCA, multiplies the found principle components by a quantity which is directly proportion to the corresponding eigenvalue times a single draw from a standard Guassian. This procedure approximately captures that object identity does not change with the color and illlumination of the picture. This is complicated to implement so for now we let it be, but maybe I will return to this blog post in the future and make this update.</p>
</section>
<section id="training-utilities" class="level1">
<h1>Training utilities</h1>
<p>We are finally nearly ready for training. We define some useful utility functions below. There are two aspects of the training which are from the paper.</p>
</section>
<section id="training-stochastic-gradient-descent-with-weight-decay" class="level1">
<h1>Training: Stochastic Gradient Descent with Weight Decay</h1>
<p>Firstly, the paper uses stochastic gradient descent with a weight decay of 0.00005. The paper mentions that this is actually important for learning and not just regularization because it results in a lower training error, apart from controlling overfitting / validation error.</p>
</section>
<section id="training-learning-rate-schedule" class="level1">
<h1>Training: Learning Rate Schedule</h1>
<p>Secondly, the paper uses a schedule where the learning rate is reduced by 10x whenever the validation loss does not improve for ten epochs. We use these settings just because they are the ones used in the paper, even though as described above our dataset is different. Apart from these two configurations, the other functions just perform useful tasks like model loading and saving, and setting the device to use a GPU if one is available.</p>
<div id="e5284ca0-651e-43fa-bb15-e6c6cc8212d5" class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> set_seed():</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Set random seed</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.initial_seed()</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_model(NUM_CLASSES, device, model_name):</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Setup model</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> model_name <span class="op">==</span> <span class="st">'alexnet'</span>:</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> AlexNet(num_classes<span class="op">=</span>NUM_CLASSES).to(device)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> set_device():</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set devices to be agnostic to whether CPU or GPU is used</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.device(<span class="st">'cuda'</span>) </span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mac M1</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> torch.backends.mps.is_available():</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.device(<span class="st">'mps'</span>) </span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.device(<span class="st">'cpu'</span>)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> save_checkpoint(model_name, CHECKPOINT_DIR, epoch, </span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>                   total_steps, optimizer, model, seed, history):</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a><span class="co">    Save checkpoint</span></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>    checkpoint_path <span class="op">=</span> os.path.join(CHECKPOINT_DIR, <span class="ss">f'</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">_best_loss.pkl'</span>)</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>    state <span class="op">=</span> {<span class="st">'model'</span>: model.state_dict()}</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>    torch.save(state, checkpoint_path)</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_optimizer(optimizer_name, model, other_params):</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a><span class="co">    Create optimizer</span></span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>    params <span class="op">=</span> model.parameters()</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> optim.SGD(params, <span class="op">**</span>other_params)</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> set_lr_schedule(optimizer, step_size<span class="op">=</span><span class="dv">1</span>, gamma<span class="op">=</span><span class="fl">0.1</span>, policy_name<span class="op">=</span><span class="st">'Step'</span>, step_size_up<span class="op">=</span><span class="dv">10</span>, base_lr<span class="op">=</span><span class="fl">0.01</span>, max_lr<span class="op">=</span><span class="fl">0.4</span>):</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a><span class="co">    Set LR scheduler</span></span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> policy_name <span class="op">==</span> <span class="st">'Step'</span>:</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> optim.lr_scheduler.StepLR(optimizer, step_size<span class="op">=</span>step_size, gamma<span class="op">=</span>gamma)</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> policy_name <span class="op">==</span> <span class="st">'Cyclic'</span>:</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> optim.lr_scheduler.CyclicLR(optimizer, base_lr<span class="op">=</span>base_lr, max_lr<span class="op">=</span>max_lr, step_size_up<span class="op">=</span>step_size_up)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="training-loop" class="level1">
<h1>Training loop</h1>
<div id="152c0d36-dbce-4fe7-9b7c-7c6c159cb681" class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> training_loop(LOG_DIR, NUM_CLASSES, model_name, </span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>                  DEVICE_IDS, TRAIN_IMG_DIR, VAL_IMG_DIR, transforms_list,</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>                  BATCH_SIZE, N_SAMPLE, optimizer_name, other_params, NUM_EPOCHS,</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>                  N_CHECK, CHECKPOINT_DIR):</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co">    This is the main</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co">    training and evaluation</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co">    loop for the model</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    logs <span class="op">=</span> PlotLosses()</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Misc. settings to make sure no errors happen</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    torch.autograd.set_detect_anomaly(<span class="va">True</span>)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prevents out of memory error when num_workers &gt; 1 in data loaders</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    torch.multiprocessing.set_sharing_strategy(<span class="st">'file_system'</span>)</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set backend</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> set_device()</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    cpu_device <span class="op">=</span> torch.device(<span class="st">'cpu'</span>)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Using the following device:"</span>)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(device)</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Make directory to store checkpoints</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>    os.makedirs(CHECKPOINT_DIR, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print the seed value</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>    seed <span class="op">=</span> set_seed()</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Used seed : </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(seed))</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create model</span></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> get_model(NUM_CLASSES, device, model_name)</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Model instance created'</span>)</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create datasets and data loaders</span></span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>    train_dataset <span class="op">=</span> get_dataset(TRAIN_IMG_DIR, transforms_list)</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Train dataset created'</span>)</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>    val_dataset <span class="op">=</span> get_dataset(VAL_IMG_DIR, transforms_list)</span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Val dataset created'</span>)</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a>    train_loader <span class="op">=</span> get_dataloader(train_dataset, BATCH_SIZE, </span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a>                                  shuffle<span class="op">=</span><span class="va">True</span>, pin_memory<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>                                  num_workers<span class="op">=</span><span class="dv">4</span>, drop_last<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>                                  subset_data<span class="op">=</span><span class="va">False</span>, N_SAMPLE<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a>    train_evaluator <span class="op">=</span> get_dataloader(train_dataset, <span class="bu">len</span>(train_dataset), </span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a>                                     shuffle<span class="op">=</span><span class="va">True</span>, pin_memory<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a>                                     num_workers<span class="op">=</span><span class="dv">4</span>, drop_last<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a>                                     subset_data<span class="op">=</span><span class="va">False</span>, N_SAMPLE<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, data <span class="kw">in</span> <span class="bu">enumerate</span>(train_evaluator):</span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a>        X_train, Y_train <span class="op">=</span> data</span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a>        X_train <span class="op">=</span> X_train.to(device)</span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a>        Y_train <span class="op">=</span> Y_train.to(device)</span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a>    val_loader <span class="op">=</span> get_dataloader(val_dataset, <span class="bu">len</span>(val_dataset), </span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a>                                shuffle<span class="op">=</span><span class="va">True</span>, pin_memory<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a>                                num_workers<span class="op">=</span><span class="dv">4</span>, drop_last<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a>                                subset_data<span class="op">=</span><span class="va">False</span>, N_SAMPLE<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb8-67"><a href="#cb8-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-68"><a href="#cb8-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-69"><a href="#cb8-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-70"><a href="#cb8-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, data <span class="kw">in</span> <span class="bu">enumerate</span>(val_loader):</span>
<span id="cb8-71"><a href="#cb8-71" aria-hidden="true" tabindex="-1"></a>        X_val, Y_val <span class="op">=</span> data</span>
<span id="cb8-72"><a href="#cb8-72" aria-hidden="true" tabindex="-1"></a>        X_val <span class="op">=</span> X_val.to(device)</span>
<span id="cb8-73"><a href="#cb8-73" aria-hidden="true" tabindex="-1"></a>        Y_val <span class="op">=</span> Y_val.to(device)</span>
<span id="cb8-74"><a href="#cb8-74" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-75"><a href="#cb8-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-76"><a href="#cb8-76" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print </span></span>
<span id="cb8-77"><a href="#cb8-77" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Dataloaders created'</span>)</span>
<span id="cb8-78"><a href="#cb8-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-79"><a href="#cb8-79" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> get_optimizer(optimizer_name, model, other_params)</span>
<span id="cb8-80"><a href="#cb8-80" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Optimizer created'</span>)</span>
<span id="cb8-81"><a href="#cb8-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-82"><a href="#cb8-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-83"><a href="#cb8-83" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Multiply LR by 1 / 10 after every 30 epochs</span></span>
<span id="cb8-84"><a href="#cb8-84" aria-hidden="true" tabindex="-1"></a>    lr_scheduler <span class="op">=</span> set_lr_schedule(optimizer, step_size<span class="op">=</span><span class="dv">30</span>, gamma<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb8-85"><a href="#cb8-85" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'LR Scheduler created...'</span>)</span>
<span id="cb8-86"><a href="#cb8-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-87"><a href="#cb8-87" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Start training!</span></span>
<span id="cb8-88"><a href="#cb8-88" aria-hidden="true" tabindex="-1"></a>    total_steps <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb8-89"><a href="#cb8-89" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Starting training...'</span>)</span>
<span id="cb8-90"><a href="#cb8-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-91"><a href="#cb8-91" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set whether to run in test mode</span></span>
<span id="cb8-92"><a href="#cb8-92" aria-hidden="true" tabindex="-1"></a>    test <span class="op">=</span> <span class="va">False</span></span>
<span id="cb8-93"><a href="#cb8-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-94"><a href="#cb8-94" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define the loss function</span></span>
<span id="cb8-95"><a href="#cb8-95" aria-hidden="true" tabindex="-1"></a>    loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb8-96"><a href="#cb8-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-97"><a href="#cb8-97" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize the dictionary where all metrics will be stored</span></span>
<span id="cb8-98"><a href="#cb8-98" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> {</span>
<span id="cb8-99"><a href="#cb8-99" aria-hidden="true" tabindex="-1"></a>        <span class="st">'acc'</span>: [],</span>
<span id="cb8-100"><a href="#cb8-100" aria-hidden="true" tabindex="-1"></a>        <span class="st">'loss'</span>: [], </span>
<span id="cb8-101"><a href="#cb8-101" aria-hidden="true" tabindex="-1"></a>        <span class="st">'val_acc'</span>: [],</span>
<span id="cb8-102"><a href="#cb8-102" aria-hidden="true" tabindex="-1"></a>        <span class="st">'val_loss'</span>: []</span>
<span id="cb8-103"><a href="#cb8-103" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb8-104"><a href="#cb8-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-105"><a href="#cb8-105" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Training loop</span></span>
<span id="cb8-106"><a href="#cb8-106" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> test:</span>
<span id="cb8-107"><a href="#cb8-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-108"><a href="#cb8-108" aria-hidden="true" tabindex="-1"></a>        min_val_loss <span class="op">=</span> np.inf</span>
<span id="cb8-109"><a href="#cb8-109" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Train for maximum number of epochs given here</span></span>
<span id="cb8-110"><a href="#cb8-110" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoch <span class="kw">in</span> tqdm(<span class="bu">range</span>(NUM_EPOCHS)):</span>
<span id="cb8-111"><a href="#cb8-111" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Initialize running loss value for this epoch</span></span>
<span id="cb8-112"><a href="#cb8-112" aria-hidden="true" tabindex="-1"></a>            running_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb8-113"><a href="#cb8-113" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Loop through the generator containing training images</span></span>
<span id="cb8-114"><a href="#cb8-114" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i, data <span class="kw">in</span> <span class="bu">enumerate</span>(train_loader):</span>
<span id="cb8-115"><a href="#cb8-115" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Retrieve inputs and labels</span></span>
<span id="cb8-116"><a href="#cb8-116" aria-hidden="true" tabindex="-1"></a>              inputs, labels <span class="op">=</span> data</span>
<span id="cb8-117"><a href="#cb8-117" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Send them to GPU </span></span>
<span id="cb8-118"><a href="#cb8-118" aria-hidden="true" tabindex="-1"></a>              inputs <span class="op">=</span> inputs.<span class="bu">type</span>(torch.FloatTensor).to(device)</span>
<span id="cb8-119"><a href="#cb8-119" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Labels</span></span>
<span id="cb8-120"><a href="#cb8-120" aria-hidden="true" tabindex="-1"></a>              labels <span class="op">=</span>  labels.<span class="bu">type</span>(torch.LongTensor).to(device)</span>
<span id="cb8-121"><a href="#cb8-121" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Zero the optimizer gradients</span></span>
<span id="cb8-122"><a href="#cb8-122" aria-hidden="true" tabindex="-1"></a>              optimizer.zero_grad()</span>
<span id="cb8-123"><a href="#cb8-123" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Forward propagation</span></span>
<span id="cb8-124"><a href="#cb8-124" aria-hidden="true" tabindex="-1"></a>              outputs <span class="op">=</span> model.forward(inputs)</span>
<span id="cb8-125"><a href="#cb8-125" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Compute loss</span></span>
<span id="cb8-126"><a href="#cb8-126" aria-hidden="true" tabindex="-1"></a>              loss <span class="op">=</span> loss_fn(outputs, labels)</span>
<span id="cb8-127"><a href="#cb8-127" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Backward propogation</span></span>
<span id="cb8-128"><a href="#cb8-128" aria-hidden="true" tabindex="-1"></a>              loss.backward()</span>
<span id="cb8-129"><a href="#cb8-129" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Weight update</span></span>
<span id="cb8-130"><a href="#cb8-130" aria-hidden="true" tabindex="-1"></a>              optimizer.step()</span>
<span id="cb8-131"><a href="#cb8-131" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb8-132"><a href="#cb8-132" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute training loss</span></span>
<span id="cb8-133"><a href="#cb8-133" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb8-134"><a href="#cb8-134" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Forward propagation</span></span>
<span id="cb8-135"><a href="#cb8-135" aria-hidden="true" tabindex="-1"></a>              out <span class="op">=</span> model.forward(X_train)</span>
<span id="cb8-136"><a href="#cb8-136" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Prediction </span></span>
<span id="cb8-137"><a href="#cb8-137" aria-hidden="true" tabindex="-1"></a>              preds <span class="op">=</span> out.argmax(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-138"><a href="#cb8-138" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Get accuracy </span></span>
<span id="cb8-139"><a href="#cb8-139" aria-hidden="true" tabindex="-1"></a>              accuracy <span class="op">=</span> <span class="bu">sum</span>(preds <span class="op">==</span> Y_train)<span class="op">/</span><span class="bu">len</span>(Y_train)</span>
<span id="cb8-140"><a href="#cb8-140" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Get loss </span></span>
<span id="cb8-141"><a href="#cb8-141" aria-hidden="true" tabindex="-1"></a>              loss <span class="op">=</span> loss_fn(out, Y_train)</span>
<span id="cb8-142"><a href="#cb8-142" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Append to history record</span></span>
<span id="cb8-143"><a href="#cb8-143" aria-hidden="true" tabindex="-1"></a>              history[<span class="st">'acc'</span>].append(accuracy.to(cpu_device))</span>
<span id="cb8-144"><a href="#cb8-144" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Append loss to history record</span></span>
<span id="cb8-145"><a href="#cb8-145" aria-hidden="true" tabindex="-1"></a>              history[<span class="st">'loss'</span>].append(loss.to(cpu_device))</span>
<span id="cb8-146"><a href="#cb8-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-147"><a href="#cb8-147" aria-hidden="true" tabindex="-1"></a>          </span>
<span id="cb8-148"><a href="#cb8-148" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute validation loss</span></span>
<span id="cb8-149"><a href="#cb8-149" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb8-150"><a href="#cb8-150" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Forward propogation</span></span>
<span id="cb8-151"><a href="#cb8-151" aria-hidden="true" tabindex="-1"></a>              out <span class="op">=</span> model.forward(X_val)</span>
<span id="cb8-152"><a href="#cb8-152" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Prediction </span></span>
<span id="cb8-153"><a href="#cb8-153" aria-hidden="true" tabindex="-1"></a>              preds <span class="op">=</span> out.argmax(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-154"><a href="#cb8-154" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Calculate accuracy</span></span>
<span id="cb8-155"><a href="#cb8-155" aria-hidden="true" tabindex="-1"></a>              accuracy <span class="op">=</span> <span class="bu">sum</span>(preds <span class="op">==</span> Y_val)<span class="op">/</span><span class="bu">len</span>(Y_val)</span>
<span id="cb8-156"><a href="#cb8-156" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Calculate loss </span></span>
<span id="cb8-157"><a href="#cb8-157" aria-hidden="true" tabindex="-1"></a>              loss <span class="op">=</span> loss_fn(out, Y_val)</span>
<span id="cb8-158"><a href="#cb8-158" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Append accuracy to history record</span></span>
<span id="cb8-159"><a href="#cb8-159" aria-hidden="true" tabindex="-1"></a>              history[<span class="st">'val_acc'</span>].append(accuracy.to(cpu_device))</span>
<span id="cb8-160"><a href="#cb8-160" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Append loss</span></span>
<span id="cb8-161"><a href="#cb8-161" aria-hidden="true" tabindex="-1"></a>              history[<span class="st">'val_loss'</span>].append(loss.to(cpu_device))</span>
<span id="cb8-162"><a href="#cb8-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-163"><a href="#cb8-163" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If loss has improved</span></span>
<span id="cb8-164"><a href="#cb8-164" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> loss <span class="op">&lt;</span> min_val_loss:</span>
<span id="cb8-165"><a href="#cb8-165" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Save checkpoint</span></span>
<span id="cb8-166"><a href="#cb8-166" aria-hidden="true" tabindex="-1"></a>              save_checkpoint(model_name, CHECKPOINT_DIR, epoch, </span>
<span id="cb8-167"><a href="#cb8-167" aria-hidden="true" tabindex="-1"></a>                              total_steps, optimizer, model, seed, history)</span>
<span id="cb8-168"><a href="#cb8-168" aria-hidden="true" tabindex="-1"></a>              <span class="co"># Minimum validation loss</span></span>
<span id="cb8-169"><a href="#cb8-169" aria-hidden="true" tabindex="-1"></a>              min_val_loss <span class="op">=</span> loss</span>
<span id="cb8-170"><a href="#cb8-170" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb8-171"><a href="#cb8-171" aria-hidden="true" tabindex="-1"></a>            metrics <span class="op">=</span> {k: v[<span class="op">-</span><span class="dv">1</span>] <span class="cf">for</span> k, v <span class="kw">in</span> history.items()}</span>
<span id="cb8-172"><a href="#cb8-172" aria-hidden="true" tabindex="-1"></a>            logs.update(metrics)</span>
<span id="cb8-173"><a href="#cb8-173" aria-hidden="true" tabindex="-1"></a>            logs.send()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="execution" class="level1">
<h1>Execution</h1>
<div id="00dd70f3-0131-4fb9-a03f-934a2c32352a" class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">'__main__'</span>:</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    MODEL_NAME <span class="op">=</span> <span class="st">'alexnet'</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    DATA_ROOT <span class="op">=</span> <span class="st">'data'</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    DATASET_NAME <span class="op">=</span> <span class="st">'imagenette2_sample'</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    INPUT_ROOT_DIR <span class="op">=</span> os.path.join(DATA_ROOT, DATASET_NAME)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    OUTPUT_DIR <span class="op">=</span> os.path.join(DATA_ROOT, <span class="ss">f'</span><span class="sc">{</span>MODEL_NAME<span class="sc">}</span><span class="ss">_data_out'</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    TRAIN_IMG_DIR <span class="op">=</span> os.path.join(INPUT_ROOT_DIR, <span class="st">'train'</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    VAL_IMG_DIR <span class="op">=</span> os.path.join(INPUT_ROOT_DIR, <span class="st">'val'</span>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    LOG_DIR <span class="op">=</span> os.path.join(OUTPUT_DIR, <span class="st">'tblogs'</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    CHECKPOINT_DIR <span class="op">=</span> os.path.join(OUTPUT_DIR , <span class="st">'models'</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    NUM_EPOCHS <span class="op">=</span> <span class="dv">100</span>  </span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    BATCH_SIZE <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    MOMENTUM <span class="op">=</span> <span class="fl">0.9</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    LR_DECAY <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    LR_INIT <span class="op">=</span> <span class="fl">0.0001</span></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>    N_SAMPLE <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>    N_CHECK <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>    IMAGE_DIM <span class="op">=</span> <span class="dv">227</span></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>    NUM_CLASSES <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>    DEVICE_IDS <span class="op">=</span> <span class="va">None</span></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>    MEANS <span class="op">=</span> [<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>]</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>    STDS <span class="op">=</span> [<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>]</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>    OPTIMIZER_NAME <span class="op">=</span> <span class="st">'SGD'</span></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>    OTHER_PARAMS <span class="op">=</span> {<span class="st">'lr'</span>: LR_INIT, }</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>    TRANSFORMS_LIST <span class="op">=</span> [transforms.CenterCrop(IMAGE_DIM),</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>                       transforms.ToTensor(),</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>                       transforms.Normalize(mean<span class="op">=</span>MEANS, std<span class="op">=</span>STDS),]</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>    training_loop(LOG_DIR, NUM_CLASSES, MODEL_NAME, </span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>                  DEVICE_IDS, TRAIN_IMG_DIR, VAL_IMG_DIR, TRANSFORMS_LIST,</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>                  BATCH_SIZE, N_SAMPLE, OPTIMIZER_NAME, OTHER_PARAMS, NUM_EPOCHS, N_CHECK, CHECKPOINT_DIR)</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="alexnet_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [26:32&lt;00:00, 15.93s/it]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy
    training             (min:    0.505, max:    0.958, cur:    0.916)
    validation           (min:    0.500, max:    0.868, cur:    0.737)
Loss
    training             (min:    0.274, max:  851.907, cur:    1.041)
    validation           (min:    1.141, max:  796.738, cur:    3.314)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
</div>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>There you have it - AlexNet almost how it was implemented in the original paper. There are still a few components missing which I may come back and add in the future:</p>
<ul>
<li><p>We use max-pooling instead of the local response normalization used by the authors. The data augmentation scheme is missing, even though the authors explicitly say that AlexNet suffers from terrible overfitting without it. This is reflected in our own results with how jagged the validation accuracy curve is.</p></li>
<li><p>There is no model parallelism implemented here because we don’t have multiple machines and in any case the hardware available to us is powerful enough to do training in a short amount of time on our reduced version of ImageNet.</p></li>
<li><p>The learning rate schedule is different from what was used in the paper so it may be interesting to see the effects of changing this to be the same as in the paper.</p></li>
</ul>
<p>However, more or less, this implementation captures the spirit of the original paper. The effects of AlexNet were far-reaching. The authors showed that GPU hardware could be effectively used to train neural networks of greater depth than had been possible up until then. They only used 2 NVIDIA GPU cards, which obviously got everyone interested in the possibilities of using more compute to train deeper models! More importantly, they showed that this greater depth was not pointless, but actually resulted in performance that smashed all the existing records on the ImageNet object recognition dataset. This opened the door for deep learning research to start flourishing in the area of computer vision. Alex Krizhevsky and Ilya Sutskever, who then had a startup called DNN Inc.&nbsp;to conduct their neural network experiments, got acquired by Google. What came next? Deeper models and more explorations of how to scale up neural network size and complexity. Stay tuned for more in the next blog posts.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© CC-By Akshat Goel</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>This page is built with ❤️ and <a href="https://quarto.org/">Quarto</a>, with a theme from <a href="https://github.com/rstudio/vetiver.rstudio.com">vetiver</a>.</p>
</div>
  </div>
</footer>




</body></html>