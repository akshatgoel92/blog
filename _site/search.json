[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my blog! This is a place for me to collect my thoughts. I’m interested in and curious about most topics, and sharing about everything I read and find out will help me understand and organize ideas in my mind. I hope you enjoy the posts!"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Akshat's Blog",
    "section": "",
    "text": "Digit Recognition Using Lenet\n\n\n\n\n\n\nml\n\n\n\n\n\n\n\n\n\nJan 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome!\n\n\n\n\n\n\nmisc\n\n\n\n\n\n\n\n\n\nDec 8, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024_12_08_intro/intro.html",
    "href": "posts/2024_12_08_intro/intro.html",
    "title": "Welcome!",
    "section": "",
    "text": "Welcome!\nHello! I’m Akshat. This is my first blog post, and also almost my first time sharing my writing on the internet. I like to read about almost anything that I can get my hands on. I have an academic background in economics, statistics, and machine learning. In my professional life, I work as a data scientist at an education NGO in New Delhi, India.\nI have many thoughts on working in the social sector, especially in technology roles, and also about economics, history, and statistics and machine learning. It is an interesting time to be in these fields, and there is a lot to learn and keep up with. I enjoy sharing what I learn from my reading and experiences with others. I hope maintaining this website will not only let me satisfy my need to share and express myself, but also keep me committed to completing the books and side projects that I start."
  },
  {
    "objectID": "posts/2024_12_08_welcome/intro.html",
    "href": "posts/2024_12_08_welcome/intro.html",
    "title": "Welcome!",
    "section": "",
    "text": "Welcome!\nHello! I’m Akshat. This is my first blog post, and also almost my first time sharing my writing on the internet. I like to read about almost anything that I can get my hands on. I have an academic background in economics, statistics, and machine learning. In my professional life, I work as a data scientist at an education NGO in New Delhi, India.\nI have many thoughts on working in the social sector, especially in technology roles, and also about economics, history, and statistics and machine learning. It is an interesting time to be in these fields, and there is a lot to learn and keep up with. I enjoy sharing what I learn from my reading and experiences with others. I hope maintaining this website will not only let me satisfy this need to share and express myself, but also keep me committed to completing the books and side projects that I start. Enjoy!"
  },
  {
    "objectID": "posts/2025_01_13_lenet/lenet.html",
    "href": "posts/2025_01_13_lenet/lenet.html",
    "title": "Digit Recognition Using Lenet",
    "section": "",
    "text": "Introduction\nIn this post, we implement Lenet, widely acknowledged to be one of the first convolutional neural networks that was used in a practical setting, and also amongst the first to be trained via the backpropogation algorithm rather than being hand-designed. The original Lenet model was developed by Yann LeCun, Leon Bottou, Yoshua Bengio and Patrick Haffner, to classify numerical digits from 0 to 9. It was accurate enough that many banks adopted it to scan the digits on the millons of checks deposited at ATMs every day. In fact, there are some ATMs which still today use the original code from the creators of Lenet!\n\nimport os\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.datasets as datasets\n\nfrom tqdm import tqdm\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.dataset import random_split\n\n\n\nThe architecture\nWe will implement Lenet-5, the version of the model that was used widely by banks to process checks at ATMs. Lenet-5 has seven layers. Three of these are convolutional layers, two are pooling layers, two are fully connected layers. This is a very small network by modern standards. Many neural network architectures published in the last decade have tens of layers, and some even have over one hundred layers.\nHowever, old and small does not mean weak. We’ll see that for the problem it was designed to solve, gray-scale hand-written digit recognition, Lenet-5 does extremely well. It actually made it to production at a large scale and performed very accurately and reliably, which is more than can be said for many far larger and fancier models being developed at companies today.\nWe stick as closely as possible to the original reference implementation that is described in the paper. Doing this, it turns out, was not as straightforward as it seems. This is because the paper was written a long time before the most recent few years of deep learning research. To complicate the issue, many implementations of Lenet that are available online deviate in ways big and small from the original paper, usually by incorporating simplifications based on convenience, and also on findings in deep learning that were not known when Lenet was first released. We point these out where we can, because at least for me, it was interesting to see all the small ways in which the impact of so much research effort ends up being reflected in even ‘simple’ code.\n\n\nLenet pooling layer\nThe Lenet pooling layer as described in the original paper is not commonly used today. First average pooling and then max. pooling came to be more commonly used, but they had not been discovered or experimented with at the time the authors were writing. Note that most online implementations do not implement the original precise pooling layer described in the paper, and either use max. pooling or average pooling.\nThe paper actually says that to pool information after the convolutional layers, they use a 2 by 2 kernel with a stride of 2 to ensure that the kernel neighborhoods don’t overlap. Each of the 4 entries in the kernel neighborhood are summed, and then passed through a linear layer with learned coefficients. In our implementation, to accomplish the summation, we use the LPPool2d method from PyTorch, with a parameter of 1 and stride of 2. The documentation tells us that this is exactly what we want.\n\nclass LenetPool(nn.Module):\n    \"\"\"Subsampling layer from LeCun et al. (1987)\"\"\"\n    def __init__(self, kernel_size, sum_stride, in_features, out_features):\n        \"\"\"Initialization\"\"\"\n        super(LenetPool, self).__init__()\n        self.sum_pool = nn.LPPool2d(1, kernel_size, stride=sum_stride)\n        self.linear = nn.Linear(in_features, out_features)\n        self.layers = nn.Sequential(self.sum_pool, self.linear)\n    \n    def forward(self, x):\n        \"\"\"Forward pass\"\"\"\n        return self.layers(x)\n\n\n\nLenet activation function\nJust like the Lenet pooling layer, the activation function described in the original paper is not commonly used today. Rectified Linear Units (ReLU) and its variants and relatives have become the default activation, and there has been a move away from sigmoidal functions like the sigmoid and tanh. This is largely to do with learning dynamics - these functions become very flat near zero and at large magnitudes, which results in low gradients and hence slower learning. However, the authors didn’t know this when they were designing Lenet. Furthermore, the activation function used in Lenet is not a vanilla tanh. There are some tweaks that the authors have made to improve performance, or so they claim.\nThe first modification is that that the input to the activation is first passed through a linear layer, or in the paper’s language, multipled by a learned weight \\(S\\) to adaptively set the slope of the activation function near its origin. Secondly, the value that the activation function outputs is then scaled by \\(A\\), a value that is hard-coded in the paper to \\(1.7159\\).\nOnline implementations tend to either use ReLU or just straight up tanh without these modifications, and performance doesn’t seem to be affected much. But we stick to this implementation as that is what’s in the paper, and it’s also cool to think that actually going through the paper makes all these differences show up.\n\nclass LenetSigmoid(nn.Module):\n    \"\"\"Activation function for Lenet-5\"\"\"\n    def __init__(self, in_features, out_features):\n        super(LenetSigmoid, self).__init__()\n        self.S = nn.Linear(in_features, out_features, bias=False)\n        self.act = nn.Tanh()\n        self.A = 1.7159\n    \n    def forward(self, x):\n        \"\"\"Forward pass\"\"\"\n        x = self.S(x)\n        x = self.act(x)\n        x = self.A*x\n        return x\n\n\n\nThe Lenet architecture\nThe Lenet architecture apart from this is straightforward, and the network given below is a faithful reproduction, apart from two interesting changes.\nThe first change is layer C3. In the original paper, the authors are careful to note that not all feature maps from S2’s output are sent to every filter in C3. Instead, there is a scheme in which each input feature map is sent to only three of the 16 filters in C3. There are two reasons for this: 1) to encourage individual features to adapt and 2) to keep the number of connections manageable due to the limited amount of computational resources available at the time. This first change reminded me of dropout regularization, which it predates by quite some time! This would have taken more work than I’m interested in putting in at the moment, but might make for a nice future extension.\nThe second change is to the output layer. The authors actually use an RBF network as an output layer. They get the network to output 84 values which is then compared to a 7 by 12 bitmap version of the target image. The class with the lowest cross-entropy loss is selected. We don’t do this because the softmax final layer for classifiers is very standard these days, and also because it doesn’t seem to effect performance much, but this is another nice future exercise, especially to keep the spirit of being authentic to what is actually in the paper.\n\nclass Lenet(nn.Module):\n    \"\"\"Lenet-5 architecture\"\"\"\n    def __init__(self, num_classes):\n        super(Lenet, self).__init__()\n        \n        # Convolutional block\n        self.c1 = nn.Conv2d(1, 6, 5)\n        self.a1 = LenetSigmoid(28, 28)\n        \n        # Pooling block\n        self.s2 = LenetPool(2, 2, 14, 14)\n        self.a2 = LenetSigmoid(14, 14)\n        \n        # Convolutional block\n        self.c3 = nn.Conv2d(6, 16, 5)\n        self.a3 = LenetSigmoid(10, 10)\n        \n        # Pooling block\n        self.s4 = LenetPool(2, 2, 5, 5)\n        self.a4 = LenetSigmoid(5, 5)\n        \n        # Flatten to prepare for fully connected blocks\n        self.flatten = nn.Flatten()\n        \n        # Fully connected block\n        self.f5 = nn.Linear(400, 120)\n        self.a5 = LenetSigmoid(120, 120)\n        \n        # Fully connected block\n        self.f6 = nn.Linear(120, 84)\n        self.a6 = LenetSigmoid(84, 84)\n        \n        # Output block\n        self.f7 = nn.Linear(84, num_classes)\n        \n        # Wrap all layers in a Sequential block\n        self.layers = nn.Sequential(self.c1, self.a1, \n                                    self.s2, self.a2,\n                                    self.c3, self.a3, \n                                    self.s4, self.a4,\n                                    self.flatten,\n                                    self.f5, self.a5, \n                                    self.f6, self.a6, \n                                    self.f7,)\n    \n    def forward(self, x):\n        \"\"\"Lenet-5 forward pass\"\"\"\n        return self.layers(x)\n\n\n\nTesting for shapes\nOne side note while doing this: testing to make sure that we are getting the correct shapes turned out to be important. Given below is a very simple utility function that prints out the output shapes from applying each layer in sequence. One silly mistake that I was making while initially doing this was testing out without a batch dimension, and so the training loop wasn’t working.\n\ndef run_tests(shape, num_classes):\n    \"\"\"Test the forward pass for shapes\"\"\"\n    \n    # Create test instance\n    x = torch.randn(shape)\n    \n    # Initialize the model\n    model = Lenet(num_classes)\n    \n    # Iterate through the layer\n    for layer in model.layers:\n        \n        # Apply each layer\n        x = layer(x)\n        \n        # Print the summary\n        print(layer.__class__.__name__, ':', x.shape)\n    \n    # Return statement\n    return x\n\n\n\nTraining / evaluation results\nGiven below is a standard evaluation loop. Note that during the preprocessing we had to resize the images to be 32 by 32 because for some reason they weren’t that size in the PyTorch dataset that we downloaded. But apart from that we just convert all the images to tensors, and apply a normalization. Note that since I am on an M1 Mac, I can use the MPS device to make sure the GPU is utilized. The results show that the loss curve decreases pretty smoothly throughout training, and we get a very high test accuracy of 98.2%, very similar to the results in the original paper!\n\nif __name__ == '__main__':\n    \n    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n    \n    # Hyperparameters\n    num_classes = 10\n    batch_size = 128\n    learning_rate = 0.001\n    epochs = 20\n    \n    # Transform for MNIST (Normalize to mean 0.5, std 0.5)\n    transform = transforms.Compose([transforms.Resize((32, 32)), \n                                    transforms.ToTensor(), \n                                    transforms.Normalize((0.5,), (0.5,))])\n\n    # Load MNIST dataset\n    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n\n    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n\n    # Initialize model, loss function, and optimizer\n    model = Lenet(num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n    # Training loop\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n\n        for batch_idx, (data, target) in tqdm(enumerate(train_loader)):\n            \n            # Sent to GPU\n            data, target = data.to(device), target.to(device)\n            \n            # Zero the gradients\n            optimizer.zero_grad()\n\n            # Forward pass\n            output = model(data)\n\n            # Compute loss\n            loss = criterion(output, target)\n            total_loss += loss.item()\n\n            # Backward pass\n            loss.backward()\n\n            # Update weights\n            optimizer.step()\n\n        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n        \n    # Evaluate the model\n    model.eval()\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            \n            \n            _, predicted = torch.max(output, 1)\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n\n    accuracy = 100 * correct / total\n    print(f\"Test Accuracy: {accuracy:.2f}%\")\n\n469it [00:17, 26.69it/s]\n\n\nEpoch 1/20, Loss: 0.3028\n\n\n469it [00:17, 26.87it/s]\n\n\nEpoch 2/20, Loss: 0.1270\n\n\n469it [00:15, 30.61it/s]\n\n\nEpoch 3/20, Loss: 0.0970\n\n\n469it [00:15, 30.85it/s]\n\n\nEpoch 4/20, Loss: 0.0822\n\n\n469it [00:15, 30.26it/s]\n\n\nEpoch 5/20, Loss: 0.0746\n\n\n469it [00:16, 29.07it/s]\n\n\nEpoch 6/20, Loss: 0.0672\n\n\n469it [00:15, 30.37it/s]\n\n\nEpoch 7/20, Loss: 0.0647\n\n\n469it [00:15, 30.53it/s]\n\n\nEpoch 8/20, Loss: 0.0597\n\n\n469it [00:15, 30.88it/s]\n\n\nEpoch 9/20, Loss: 0.0532\n\n\n469it [00:15, 30.61it/s]\n\n\nEpoch 10/20, Loss: 0.0555\n\n\n469it [00:15, 30.67it/s]\n\n\nEpoch 11/20, Loss: 0.0521\n\n\n469it [00:15, 30.74it/s]\n\n\nEpoch 12/20, Loss: 0.0520\n\n\n469it [00:15, 30.47it/s]\n\n\nEpoch 13/20, Loss: 0.0511\n\n\n469it [00:15, 30.45it/s]\n\n\nEpoch 14/20, Loss: 0.0472\n\n\n469it [00:15, 30.34it/s]\n\n\nEpoch 15/20, Loss: 0.0520\n\n\n469it [00:16, 28.73it/s]\n\n\nEpoch 16/20, Loss: 0.0474\n\n\n469it [00:15, 30.16it/s]\n\n\nEpoch 17/20, Loss: 0.0471\n\n\n469it [00:15, 29.87it/s]\n\n\nEpoch 18/20, Loss: 0.0473\n\n\n469it [00:15, 30.37it/s]\n\n\nEpoch 19/20, Loss: 0.0467\n\n\n469it [00:15, 30.50it/s]\n\n\nEpoch 20/20, Loss: 0.0438\nTest Accuracy: 97.86%\n\n\n\n\nConclusion\nThere you have it, Lenet-5 in all (most) of its splendor! The most fun I had while writing this post is realizing the small implementation differences between the original paper and different versions online, including some textbooks! It turns out, which in many ways is expected, that these changes don’t impact performance much, but they were still surprising to see. Lenet was one of the first examples of how neural network approaches could be competitive with the then dominant machine learning paradigm of support vector machines, and served as an inspiration to the early deep learning pioneers that their ideas were promising and could be turned into useful innovations."
  },
  {
    "objectID": "posts/intro.html",
    "href": "posts/intro.html",
    "title": "Welcome!",
    "section": "",
    "text": "Welcome!\nHello! I’m Akshat. This is my first blog post, and also almost my first time sharing my writing on the internet. I like to read about almost anything that I can get my hands on. I have an academic background in economics, statistics, and machine learning. In my professional life, I work as a data scientist at an education NGO in New Delhi, India.\nI have many thoughts on working in the social sector, especially in technology roles, and also about economics, history, and statistics and machine learning. It is an interesting time to be in these fields, and there is a lot to learn and keep up with. I enjoy sharing what I learn from my reading and experiences with others. I hope maintaining this website will not only let me satisfy this need to share and express myself, but also keep me committed to completing the books and side projects that I start. Enjoy!"
  },
  {
    "objectID": "posts/lenet.html",
    "href": "posts/lenet.html",
    "title": "Digit Recognition Using Lenet",
    "section": "",
    "text": "Introduction\nIn this post, we implement Lenet, widely acknowledged to be one of the first convolutional neural networks that was used in a practical setting, and also amongst the first to be trained via the backpropogation algorithm rather than being hand-designed. The original Lenet model was developed by Yann LeCun, Leon Bottou, Yoshua Bengio and Patrick Haffner, to classify numerical digits from 0 to 9. It was accurate enough that many banks adopted it to scan the digits on the millons of checks deposited at ATMs every day. In fact, there are some ATMs which still today use the original code from the creators of Lenet!\n\nimport os\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.datasets as datasets\n\nfrom tqdm import tqdm\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.dataset import random_split\n\n\n\nThe architecture\nWe will implement Lenet-5, the version of the model that was used widely by banks to process checks at ATMs. Lenet-5 has seven layers. Three of these are convolutional layers, two are pooling layers, two are fully connected layers. This is a very small network by modern standards. Many neural network architectures published in the last decade have tens of layers, and some even have over one hundred layers.\nHowever, old and small does not mean weak. We’ll see that for the problem it was designed to solve, gray-scale hand-written digit recognition, Lenet-5 does extremely well. It actually made it to production at a large scale and performed very accurately and reliably, which is more than can be said for many far larger and fancier models being developed at companies today.\nWe stick as closely as possible to the original reference implementation that is described in the paper. Doing this, it turns out, is not straightforward. This is because the paper was written a long time back, before the most recent few years of deep learning research. To complicate things, many implementations of Lenet available online deviate in ways big and small from the original paper, usually by incorporating convenient simplifications, and also on findings that were not known when Lenet was first released. We point these out where we can, because at least for me, it was interesting to see all the small ways in which the impact of so much research effort ends up being reflected in even ‘simple’ code.\n\n\nLenet pooling layer\nThe Lenet pooling layer as described in the original paper is not commonly used today. Average pooling and max. pooling have come to be more commonly used, but they had not been discovered or experimented with at the time the authors were writing. Note that most online implementations do not implement the original precise pooling layer described in the paper.\nThe paper actually pools information after the convolutional layers in a specific way. First, 2 by 2 kernel with a stride of 2 is passed over the input. These parameters are chosen to ensure that the kernel neighborhoods don’t overlap. Each of the 4 entries in the kernel neighborhood are then summed, and passed through a linear layer with learned coefficients. In our implementation, to accomplish the summation, we use the LPPool2d method from PyTorch, with a parameter of 1 and stride of 2. The documentation tells us that this is exactly what we want.\n\nclass LenetPool(nn.Module):\n    \"\"\"Subsampling layer from LeCun et al. (1987)\"\"\"\n    def __init__(self, kernel_size, sum_stride, in_features, out_features):\n        \"\"\"Initialization\"\"\"\n        super(LenetPool, self).__init__()\n        self.sum_pool = nn.LPPool2d(1, kernel_size, stride=sum_stride)\n        self.linear = nn.Linear(in_features, out_features)\n        self.layers = nn.Sequential(self.sum_pool, self.linear)\n    \n    def forward(self, x):\n        \"\"\"Forward pass\"\"\"\n        return self.layers(x)\n\n\n\nLenet activation function\nJust like the Lenet pooling layer, the activation function described in the original paper is not commonly used today. Rectified Linear Units (ReLU) and its variants and relatives have become the default activation, and there has been a move away from sigmoidal functions like the sigmoid and tanh. This is largely to do with learning dynamics - these functions become very flat near zero and at large magnitudes, which results in low gradients and hence slower learning. However, the authors didn’t know this when they were designing Lenet. Furthermore, the activation function used in Lenet is not a vanilla tanh. There are some tweaks that the authors have made which they thought would improve performance.\nThe first modification is that that the input to the activation is first passed through a linear layer, or in the paper’s language, multipled by a learned weight \\(S\\) to adaptively set the slope of the activation function near its origin. Secondly, the activation function output is then scaled by \\(A\\), a value that is hard-coded in the paper to \\(1.7159\\).\nOnline implementations tend to either use ReLU or just straight up tanh without these modifications, and performance doesn’t seem to be affected much. But we stick to this implementation as that is what’s in the paper. It’s cool to think that actually going through the original work makes all these differences show up.\n\nclass LenetSigmoid(nn.Module):\n    \"\"\"Activation function for Lenet-5\"\"\"\n    def __init__(self, in_features, out_features):\n        super(LenetSigmoid, self).__init__()\n        self.S = nn.Linear(in_features, out_features, bias=False)\n        self.act = nn.Tanh()\n        self.A = 1.7159\n    \n    def forward(self, x):\n        \"\"\"Forward pass\"\"\"\n        x = self.S(x)\n        x = self.act(x)\n        x = self.A*x\n        return x\n\n\n\nThe Lenet architecture\nThe Lenet architecture apart from this is straightforward, and the network given below is a faithful reproduction, apart from two interesting changes.\nThe first change is layer C3. In the original paper, the authors are careful to note that not all feature maps from S2’s output are sent to every filter in C3. Instead, there is a scheme in which each input feature map is sent to only three of the 16 filters in C3. There are two reasons for this: 1) to encourage individual features to adapt and 2) to keep the number of connections manageable due to the limited amount of computational resources available at the time. This first change reminded me of dropout regularization, which it predates by quite some time! This would have taken more work than I’m interested in putting in at the moment, but might make for a nice future extension.\nThe second change is to the output layer. The authors actually use an RBF network as an output layer. They get the network to output 84 values which is then compared to a 7 by 12 bitmap version of the target image. The class with the lowest cross-entropy loss is selected. We don’t do this because the softmax final layer for classifiers is very standard these days, and also because it doesn’t seem to effect performance much, but this is another nice future exercise, especially to keep the spirit of being authentic to what is actually in the paper.\n\nclass Lenet(nn.Module):\n    \"\"\"Lenet-5 architecture\"\"\"\n    def __init__(self, num_classes):\n        super(Lenet, self).__init__()\n        \n        # Convolutional block\n        self.c1 = nn.Conv2d(1, 6, 5)\n        self.a1 = LenetSigmoid(28, 28)\n        \n        # Pooling block\n        self.s2 = LenetPool(2, 2, 14, 14)\n        self.a2 = LenetSigmoid(14, 14)\n        \n        # Convolutional block\n        self.c3 = nn.Conv2d(6, 16, 5)\n        self.a3 = LenetSigmoid(10, 10)\n        \n        # Pooling block\n        self.s4 = LenetPool(2, 2, 5, 5)\n        self.a4 = LenetSigmoid(5, 5)\n        \n        # Flatten to prepare for fully connected blocks\n        self.flatten = nn.Flatten()\n        \n        # Fully connected block\n        self.f5 = nn.Linear(400, 120)\n        self.a5 = LenetSigmoid(120, 120)\n        \n        # Fully connected block\n        self.f6 = nn.Linear(120, 84)\n        self.a6 = LenetSigmoid(84, 84)\n        \n        # Output block\n        self.f7 = nn.Linear(84, num_classes)\n        \n        # Wrap all layers in a Sequential block\n        self.layers = nn.Sequential(self.c1, self.a1, \n                                    self.s2, self.a2,\n                                    self.c3, self.a3, \n                                    self.s4, self.a4,\n                                    self.flatten,\n                                    self.f5, self.a5, \n                                    self.f6, self.a6, \n                                    self.f7,)\n    \n    def forward(self, x):\n        \"\"\"Lenet-5 forward pass\"\"\"\n        return self.layers(x)\n\n\n\nTesting for shapes\nOne side note while doing this: testing to make sure that we are getting the correct shapes turned out to be important. Given below is a very simple utility function that prints out the output shapes from applying each layer in sequence. One silly mistake that I was making while initially doing this was testing out without a batch dimension, and so the training loop wasn’t working.\n\ndef run_tests(shape, num_classes):\n    \"\"\"Test the forward pass for shapes\"\"\"\n    \n    # Create test instance\n    x = torch.randn(shape)\n    \n    # Initialize the model\n    model = Lenet(num_classes)\n    \n    # Iterate through the layer\n    for layer in model.layers:\n        \n        # Apply each layer\n        x = layer(x)\n        \n        # Print the summary\n        print(layer.__class__.__name__, ':', x.shape)\n    \n    # Return statement\n    return x\n\n\n\nTraining / evaluation results\nGiven below is a standard training and evaluation loop. Note that during the preprocessing we had to resize the images to be 32 by 32 because for some reason they weren’t that size in the PyTorch dataset that we downloaded. But apart from that we just convert all the images to tensors, and apply a normalization. Note that since I am on an M1 Mac, I can use the MPS device to make sure the GPU is utilized. The results show that the loss curve decreases pretty smoothly throughout training, and we get a very high test accuracy of more than 97 %, very similar to the results in the original paper!\n\nif __name__ == '__main__':\n    \n    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n    \n    # Hyperparameters\n    num_classes = 10\n    batch_size = 128\n    learning_rate = 0.001\n    epochs = 20\n    \n    # Transform for MNIST (Normalize to mean 0.5, std 0.5)\n    transform = transforms.Compose([transforms.Resize((32, 32)), \n                                    transforms.ToTensor(), \n                                    transforms.Normalize((0.5,), (0.5,))])\n\n    # Load MNIST dataset\n    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n\n    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n\n    # Initialize model, loss function, and optimizer\n    model = Lenet(num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n    # Training loop\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n\n        for batch_idx, (data, target) in tqdm(enumerate(train_loader)):\n            \n            # Sent to GPU\n            data, target = data.to(device), target.to(device)\n            \n            # Zero the gradients\n            optimizer.zero_grad()\n\n            # Forward pass\n            output = model(data)\n\n            # Compute loss\n            loss = criterion(output, target)\n            total_loss += loss.item()\n\n            # Backward pass\n            loss.backward()\n\n            # Update weights\n            optimizer.step()\n\n        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n        \n    # Evaluate the model\n    model.eval()\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            \n            \n            _, predicted = torch.max(output, 1)\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n\n    accuracy = 100 * correct / total\n    print(f\"Test Accuracy: {accuracy:.2f}%\")\n\n469it [00:17, 26.69it/s]\n\n\nEpoch 1/20, Loss: 0.3028\n\n\n469it [00:17, 26.87it/s]\n\n\nEpoch 2/20, Loss: 0.1270\n\n\n469it [00:15, 30.61it/s]\n\n\nEpoch 3/20, Loss: 0.0970\n\n\n469it [00:15, 30.85it/s]\n\n\nEpoch 4/20, Loss: 0.0822\n\n\n469it [00:15, 30.26it/s]\n\n\nEpoch 5/20, Loss: 0.0746\n\n\n469it [00:16, 29.07it/s]\n\n\nEpoch 6/20, Loss: 0.0672\n\n\n469it [00:15, 30.37it/s]\n\n\nEpoch 7/20, Loss: 0.0647\n\n\n469it [00:15, 30.53it/s]\n\n\nEpoch 8/20, Loss: 0.0597\n\n\n469it [00:15, 30.88it/s]\n\n\nEpoch 9/20, Loss: 0.0532\n\n\n469it [00:15, 30.61it/s]\n\n\nEpoch 10/20, Loss: 0.0555\n\n\n469it [00:15, 30.67it/s]\n\n\nEpoch 11/20, Loss: 0.0521\n\n\n469it [00:15, 30.74it/s]\n\n\nEpoch 12/20, Loss: 0.0520\n\n\n469it [00:15, 30.47it/s]\n\n\nEpoch 13/20, Loss: 0.0511\n\n\n469it [00:15, 30.45it/s]\n\n\nEpoch 14/20, Loss: 0.0472\n\n\n469it [00:15, 30.34it/s]\n\n\nEpoch 15/20, Loss: 0.0520\n\n\n469it [00:16, 28.73it/s]\n\n\nEpoch 16/20, Loss: 0.0474\n\n\n469it [00:15, 30.16it/s]\n\n\nEpoch 17/20, Loss: 0.0471\n\n\n469it [00:15, 29.87it/s]\n\n\nEpoch 18/20, Loss: 0.0473\n\n\n469it [00:15, 30.37it/s]\n\n\nEpoch 19/20, Loss: 0.0467\n\n\n469it [00:15, 30.50it/s]\n\n\nEpoch 20/20, Loss: 0.0438\nTest Accuracy: 97.86%\n\n\n\n\nConclusion\nThere you have it, Lenet-5 in all (most) of its splendor! The most fun I had while writing this post is realizing the small implementation differences between the original paper and different versions online, including some textbooks! It turns out, which in many ways is expected, that these changes don’t impact performance much, but they were still surprising to see. Lenet was one of the first examples of how neural network approaches could be competitive with the then dominant machine learning paradigm of support vector machines, and served as an inspiration to the early deep learning pioneers that their ideas were promising and could be turned into useful innovations."
  }
]