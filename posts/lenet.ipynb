{
 "cells": [
  {
   "cell_type": "raw",
   "id": "dda43edf-2a6d-43e2-b31d-46cb188ed0d3",
   "metadata": {},
   "source": [
    "---\n",
    "title: Digit Recognition Using Lenet\n",
    "date: 2025-01-12\n",
    "categories: [ml]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d94a8b-0494-41ae-99fb-f2d9737be465",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "In this post, we implement Lenet, widely acknowledged to be one of the first convolutional neural networks that was used in a practical setting, and also amongst the first to be trained via the backpropogation algorithm rather than being hand-designed. The original Lenet model was developed by Yann LeCun, Leon Bottou, Yoshua Bengio and Patrick Haffner, to classify numerical digits from 0 to 9. It was accurate enough that many banks adopted it to scan the digits on the millons of checks deposited at ATMs every day. In fact, there are some ATMs which still today use the original code from the creators of Lenet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80e8b4c-f501-43d8-bb02-1fe75ce881db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708da286-c003-4963-83db-f65aad9b555f",
   "metadata": {},
   "source": [
    "# The architecture\n",
    "\n",
    "We will implement Lenet-5, the version of the model that was used widely by banks to process checks at ATMs. Lenet-5 has seven layers. Three of these are convolutional layers, two are pooling layers, two are fully connected layers. This is a very small network by modern standards. Many neural network architectures published in the last decade have tens of layers, and some even have over one hundred layers. \n",
    "\n",
    "However, old and small does not mean weak. We'll see that for the problem it was designed to solve, gray-scale hand-written digit recognition, Lenet-5 does extremely well. It actually made it to production at a large scale and performed very accurately and reliably, which is more than can be said for many far larger and fancier models being developed at companies today.\n",
    "\n",
    "\n",
    "We stick as closely as possible to the original reference implementation that is described in the paper. Doing this, it turns out, is not straightforward. This is because the paper was written a long time back, before the most recent few years of deep learning research. To complicate things, many implementations of Lenet available online deviate in ways big and small from the original paper, usually by incorporating convenient simplifications, and also on findings that were not known when Lenet was first released. We point these out where we can, because at least for me, it was interesting to see all the small ways in which the impact of so much research effort ends up being reflected in even 'simple' code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b15f68-3c90-4a0c-8c04-b37eff4c1c80",
   "metadata": {},
   "source": [
    "# Lenet pooling layer\n",
    "\n",
    "The Lenet pooling layer as described in the original paper is not commonly used today. Average pooling and max. pooling have come to be more commonly used, but they had not been discovered or experimented with at the time the authors were writing. Note that most online implementations do not implement the original precise pooling layer described in the paper.\n",
    "\n",
    "The paper actually pools information after the convolutional layers in a specific way. First, 2 by 2 kernel with a stride of 2 is passed over the input. These parameters are chosen to ensure that the kernel neighborhoods don't overlap. Each of the 4 entries in the kernel neighborhood are then summed, and passed through a linear layer with learned coefficients. In our implementation, to accomplish the summation, we use the LPPool2d method from PyTorch, with a parameter of 1 and stride of 2. The documentation tells us that this is exactly what we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ae67b6-db27-49e9-8cf2-f4d0762f62ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LenetPool(nn.Module):\n",
    "    \"\"\"Subsampling layer from LeCun et al. (1987)\"\"\"\n",
    "    def __init__(self, kernel_size, sum_stride, in_features, out_features):\n",
    "        \"\"\"Initialization\"\"\"\n",
    "        super(LenetPool, self).__init__()\n",
    "        self.sum_pool = nn.LPPool2d(1, kernel_size, stride=sum_stride)\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        self.layers = nn.Sequential(self.sum_pool, self.linear)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9ef356-3108-4168-a506-dee71020ccbe",
   "metadata": {},
   "source": [
    "# Lenet activation function\n",
    "\n",
    "Just like the Lenet pooling layer, the activation function described in the original paper is not commonly used today. Rectified Linear Units (ReLU) and its variants and relatives have become the default activation, and there has been a move away from sigmoidal functions like the sigmoid and tanh. This is largely to do with learning dynamics - these functions become very flat near zero and at large magnitudes, which results in low gradients and hence slower learning. However, the authors didn't know this when they were designing Lenet. Furthermore, the activation function used in Lenet is not a vanilla tanh.  There are some tweaks that the authors have made which they thought would improve performance.\n",
    "\n",
    "The first modification is that that the input to the activation is first passed through a linear layer, or in the paper's language, multipled by a learned weight $S$ to adaptively set the slope of the activation function near its origin. Secondly, the activation function output is then scaled by $A$, a value that is hard-coded in the paper to $1.7159$. \n",
    "\n",
    "Online implementations tend to either use ReLU or just straight up tanh without these modifications, and performance doesn't seem to be affected much. But we stick to this implementation as that is what's in the paper. It's cool to think that actually going through the original work makes all these differences show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7218cf-aa01-4307-beba-6489d2db8a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LenetSigmoid(nn.Module):\n",
    "    \"\"\"Activation function for Lenet-5\"\"\"\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(LenetSigmoid, self).__init__()\n",
    "        self.S = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.act = nn.Tanh()\n",
    "        self.A = 1.7159\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        x = self.S(x)\n",
    "        x = self.act(x)\n",
    "        x = self.A*x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6250b16-7ade-4e9d-bf0e-2320f96d6c7a",
   "metadata": {},
   "source": [
    "# The Lenet architecture\n",
    "\n",
    "The Lenet architecture apart from this is straightforward, and the network given below is a faithful reproduction, apart from two interesting changes.\n",
    "\n",
    "The first change is layer C3. In the original paper, the authors are careful to note that not all feature maps from S2's output are sent to every filter in C3. Instead, there is a scheme in which each input feature map is sent to only three of the 16 filters in C3. There are two reasons for this: 1) to encourage individual features to adapt and 2) to keep the number of connections manageable due to the limited amount of computational resources available at the time. This first change reminded me of dropout regularization, which it predates by quite some time! This would have taken more work than I'm interested in putting in at the moment, but might make for a nice future extension. \n",
    "\n",
    "The second change is to the output layer. The authors actually use an RBF network as an output layer. They get the network to output 84 values which is then compared to a 7 by 12 bitmap version of the target image. The class with the lowest cross-entropy loss is selected. We don't do this because the softmax final layer for classifiers is very standard these days, and also because it doesn't seem to effect performance much, but this is another nice future exercise, especially to keep the spirit of being authentic to what is actually in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238c6f28-da8b-4c83-92f3-c405eea5d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lenet(nn.Module):\n",
    "    \"\"\"Lenet-5 architecture\"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super(Lenet, self).__init__()\n",
    "        \n",
    "        # Convolutional block\n",
    "        self.c1 = nn.Conv2d(1, 6, 5)\n",
    "        self.a1 = LenetSigmoid(28, 28)\n",
    "        \n",
    "        # Pooling block\n",
    "        self.s2 = LenetPool(2, 2, 14, 14)\n",
    "        self.a2 = LenetSigmoid(14, 14)\n",
    "        \n",
    "        # Convolutional block\n",
    "        self.c3 = nn.Conv2d(6, 16, 5)\n",
    "        self.a3 = LenetSigmoid(10, 10)\n",
    "        \n",
    "        # Pooling block\n",
    "        self.s4 = LenetPool(2, 2, 5, 5)\n",
    "        self.a4 = LenetSigmoid(5, 5)\n",
    "        \n",
    "        # Flatten to prepare for fully connected blocks\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Fully connected block\n",
    "        self.f5 = nn.Linear(400, 120)\n",
    "        self.a5 = LenetSigmoid(120, 120)\n",
    "        \n",
    "        # Fully connected block\n",
    "        self.f6 = nn.Linear(120, 84)\n",
    "        self.a6 = LenetSigmoid(84, 84)\n",
    "        \n",
    "        # Output block\n",
    "        self.f7 = nn.Linear(84, num_classes)\n",
    "        \n",
    "        # Wrap all layers in a Sequential block\n",
    "        self.layers = nn.Sequential(self.c1, self.a1, \n",
    "                                    self.s2, self.a2,\n",
    "                                    self.c3, self.a3, \n",
    "                                    self.s4, self.a4,\n",
    "                                    self.flatten,\n",
    "                                    self.f5, self.a5, \n",
    "                                    self.f6, self.a6, \n",
    "                                    self.f7,)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Lenet-5 forward pass\"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1030f97-e41b-4af4-9335-07c857e1da43",
   "metadata": {},
   "source": [
    "# Testing for shapes\n",
    "\n",
    "One side note while doing this: testing to make sure that we are getting the correct shapes turned out to be important. Given below is a very simple utility function that prints out the output shapes from applying each layer in sequence. One silly mistake that I was making while initially doing this was testing out without a batch dimension, and so the training loop wasn't working. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4558daf3-5e9c-4061-a6e3-ce9cc48bee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests(shape, num_classes):\n",
    "    \"\"\"Test the forward pass for shapes\"\"\"\n",
    "    \n",
    "    # Create test instance\n",
    "    x = torch.randn(shape)\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = Lenet(num_classes)\n",
    "    \n",
    "    # Iterate through the layer\n",
    "    for layer in model.layers:\n",
    "        \n",
    "        # Apply each layer\n",
    "        x = layer(x)\n",
    "        \n",
    "        # Print the summary\n",
    "        print(layer.__class__.__name__, ':', x.shape)\n",
    "    \n",
    "    # Return statement\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97913ba5-46db-4f92-8417-20ac64111a81",
   "metadata": {},
   "source": [
    "# Training / evaluation results\n",
    "\n",
    "Given below is a standard training and evaluation loop. Note that during the preprocessing we had to resize the images to be 32 by 32 because for some reason they weren't that size in the PyTorch dataset that we downloaded. But apart from that we just convert all the images to tensors, and apply a normalization. Note that since I am on an M1 Mac, I can use the MPS device to make sure the GPU is utilized. The results show that the loss curve decreases pretty smoothly throughout training, and we get a very high test accuracy of more than 97 %, very similar to the results in the original paper!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae875d7-b884-47f3-8c41-61a9f629437a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:17, 26.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.3028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:17, 26.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Loss: 0.1270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:15, 30.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Loss: 0.0970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:15, 30.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Loss: 0.0822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:15, 30.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Loss: 0.0746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:16, 29.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Loss: 0.0672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:15, 30.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Loss: 0.0647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:15, 30.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Loss: 0.0597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:15, 30.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Loss: 0.0532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:15, 30.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Loss: 0.0555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:15, 30.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Loss: 0.0521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:15, 30.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Loss: 0.0520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:15, 30.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Loss: 0.0511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:15, 30.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Loss: 0.0472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:15, 30.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Loss: 0.0520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:16, 28.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Loss: 0.0474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:15, 30.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Loss: 0.0471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:15, 29.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Loss: 0.0473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:15, 30.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Loss: 0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:15, 30.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Loss: 0.0438\n",
      "Test Accuracy: 97.86%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    \n",
    "    # Hyperparameters\n",
    "    num_classes = 10\n",
    "    batch_size = 128\n",
    "    learning_rate = 0.001\n",
    "    epochs = 20\n",
    "    \n",
    "    # Transform for MNIST (Normalize to mean 0.5, std 0.5)\n",
    "    transform = transforms.Compose([transforms.Resize((32, 32)), \n",
    "                                    transforms.ToTensor(), \n",
    "                                    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "    # Load MNIST dataset\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = Lenet(num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch_idx, (data, target) in tqdm(enumerate(train_loader)):\n",
    "            \n",
    "            # Sent to GPU\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(data)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "        \n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            \n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd48912-5947-4343-9213-7195386161d6",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "There you have it, Lenet-5 in all (most) of its splendor! The most fun I had while writing this post is realizing the small implementation differences between the original paper and different versions online, including some textbooks! It turns out, which in many ways is expected, that these changes don't impact performance much, but they were still surprising to see. Lenet was one of the first examples of how neural network approaches could be competitive with the then dominant machine learning paradigm of support vector machines, and served as an inspiration to the early deep learning pioneers that their ideas were promising and could be turned into useful innovations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
